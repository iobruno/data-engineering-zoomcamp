{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232d3f5c-f2dd-481f-ae8e-ef094e730a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import environ as env\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, dayofmonth\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a62ca-14ce-448e-bb21-b4a8c4bb173d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed70919a-1c75-4fef-96b2-e9a883189a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/spark_jars/\n",
    "!wget https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar -P /tmp/spark_jars -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f21eac-4d77-4023-8b27-089928c16c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "        .setMaster('local[*]') \\\n",
    "        .setAppName(\"pyspark-playground\") \\\n",
    "        .set(\"spark.cores.max\", 4) \\\n",
    "        .set(\"spark.driver.memory\", \"2g\") \\\n",
    "        .set(\"spark.executor.memory\", \"8g\") \\\n",
    "        .set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "        .set(\"spark.jars\", \"/tmp/spark_jars/gcs-connector-latest-hadoop2.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc346ebf-2848-42f6-9613-cf810673ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 23:24:20 WARN Utils: Your hostname, magi.local resolves to a loopback address: 127.0.0.1; using 192.168.15.29 instead (on interface en0)\n",
      "23/11/26 23:24:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/11/26 23:24:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", env[\"GOOGLE_APPLICATION_CREDENTIALS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1cf602-ea4f-4525-9394-7fd462681a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfc512-824a-4c99-af3c-66f384aba4f9",
   "metadata": {},
   "source": [
    "## Load Datasets from GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc13a3-43d9-491d-abf5-fd00e3d55214",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FHV HV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22456092-e53c-4df1-baf7-f78861433a32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv = spark.read.parquet(\"gs://iobruno-lakehouse-raw/nyc_trip_record_data/fhvhv/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475dad1e-6770-4987-81c3-0f0002e07174",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv = fhvhv.select(\n",
    "    col('dispatching_base_num'),\n",
    "    col('Affiliated_base_number').alias('affiliated_base_num'),\n",
    "    col('PULocationID').alias('pickup_location_id'),\n",
    "    col('pickup_datetime').cast('timestamp'),\n",
    "    col('DOLocationID').alias('dropoff_location_id'),\n",
    "    col('dropoff_datetime').cast('timestamp'),\n",
    "    col('SR_Flag').alias('sr_flag'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbbe6e36-94a1-48fb-875a-9d9ebd5dc13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhvhv.createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dbd0fb-dccd-47d5-9879-ff2269776c31",
   "metadata": {},
   "source": [
    "### Zone Lookup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84329e08-b7f0-4b41-9b85-0cf08ef8c13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones_schema = StructType([\n",
    "    StructField(\"LocationID\", IntegerType(), True),\n",
    "    StructField(\"Borough\", StringType(), True),\n",
    "    StructField(\"Zone\", StringType(), True),\n",
    "    StructField(\"service_zone\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda76359-88cc-4b32-a7c7-ff3b48c51097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones = spark.read.option(\"header\", True)\\\n",
    "            .schema(zones_schema)\\\n",
    "            .csv(\"gs://iobruno-lakehouse-raw/nyc_trip_record_data/zone_lookup/*.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139a31ea-2546-4b47-b728-172d5df9b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = zones.select(\n",
    "    col('LocationID').alias('location_id'),\n",
    "    col('Borough').alias('borough'),\n",
    "    col('Zone').alias('zone'),\n",
    "    col('service_zone')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7347b30-97d5-4b47-99d6-63d38a579ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca37d5-a578-4572-9713-f11880cf8239",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835f303-8b53-4803-ba43-adb6873af658",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1\n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f764da54-67b5-4d66-acac-f34bccc5a0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d835f4-cba9-40a9-b499-930ebb7585f9",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons. We will use this dataset for all the remaining questions.  \n",
    "Repartition it to 12 partitions and save it to parquet. What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB). Select the answer which most closely matches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f6fd1c-d391-4915-835e-f31fad85a88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"SELECT * FROM fhvhv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b75697-43b7-40fd-8425-d1d660d8a4af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(12)\\\n",
    "    .write\\\n",
    "    .option(\"compression\", \"snappy\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"/tmp/dtc/fhvhv-week5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ddd303-5458-409c-8cdc-5b20076e56a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 563408\n",
      "-rw-r--r--  1 iobruno  wheel     0B Nov 26 23:24 _SUCCESS\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00000-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00001-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00002-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00003-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00004-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00005-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00006-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00007-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00008-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00009-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00010-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n",
      "-rw-r--r--  1 iobruno  wheel    22M Nov 26 23:24 part-00011-53cf477f-3e02-4dec-8ad5-ead5080b28b0-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /tmp/dtc/fhvhv-week5/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a31ba-76c8-4964-a4c1-ba1279eea57c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3\n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15? Consider only trips that started on June 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9d6d612-4f82-4a2e-af90-9ada87b4d359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(month=6, day=15, num_trips=452470)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH trips_per_month_day AS (\n",
    "        SELECT\n",
    "            month(pickup_datetime) as month,\n",
    "            dayofmonth(pickup_datetime) as day, \n",
    "            count(1) as num_trips\n",
    "        FROM fhvhv\n",
    "        GROUP BY month(pickup_datetime), dayofmonth(pickup_datetime)\n",
    "    )\n",
    "\n",
    "    SELECT * FROM trips_per_month_day \n",
    "    WHERE month = 6 AND day = 15\n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e0205-73fb-4462-b280-b71bb74cc680",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip. How long was the longest trip in Hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0792b43b-36a6-463a-ae42-02c316d5cc26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(duration_hours=66.8788888888889, rnk=1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH trip_records AS (\n",
    "        SELECT\n",
    "            pickup_location_id,\n",
    "            dropoff_location_id,\n",
    "            pickup_datetime,\n",
    "            dropoff_datetime,\n",
    "            (CAST(dropoff_datetime as LONG) - CAST(pickup_datetime as LONG)) as duration_secs\n",
    "        FROM \n",
    "            fhvhv\n",
    "    )\n",
    "        \n",
    "    SELECT \n",
    "        duration_secs/3600 as duration_hours,\n",
    "        dense_rank() OVER (ORDER BY duration_secs DESC) as rnk\n",
    "    FROM trip_records t\n",
    "\n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e08bed-582a-4aa6-8537-9ddad4b513c8",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark [Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv).  \n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ab7cf3-48f4-471b-9164-6568899c3ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(pickup_location_id=61, zone='Crown Heights North', num_trips=231279, rnk=1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH trips_per_location AS (\n",
    "        SELECT\n",
    "            f.pickup_location_id,\n",
    "            count(1) as num_trips,\n",
    "            dense_rank() OVER (ORDER BY count(1) DESC) as rnk\n",
    "        FROM\n",
    "            fhvhv f\n",
    "        GROUP BY\n",
    "            f.pickup_location_id\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        t.pickup_location_id,\n",
    "        pu.zone,\n",
    "        t.num_trips,\n",
    "        t.rnk\n",
    "    FROM\n",
    "        trips_per_location t\n",
    "    INNER JOIN zones pu\n",
    "        ON t.pickup_location_id = pu.location_id\n",
    "    WHERE\n",
    "        t.rnk = 1\n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e6051-1fb5-45bd-8241-a127d4fcae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
