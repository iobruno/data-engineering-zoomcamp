version: "3.9"

x-spark-image: &spark-image bitnami/spark:${BITNAMI_SPARK_VERSION:-3.5.0}
x-hive-image:  &hive-image  apache/hive:${HIVE_VERSION:-4.0.0-beta-1}
x-postgres-image: &postgres-image postgres:${POSTGRES_VERSION:-16-alpine}

x-spark-common: &spark-common
  image: *spark-image
  environment: 
    &spark-common-env
    SPARK_RPC_AUTHENTICATION_ENABLED: 'no'
    SPARK_RPC_ENCRYPTION_ENABLED: 'no'
    SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: 'no'
    SPARK_SSL_ENABLED: 'no'
    SPARK_USER: 'spark'
  volumes:
    - ${GOOGLE_APPLICATION_CREDENTIALS:-}:/.gcp/gcp_credentials.json
    - spark_jars:/spark-jars
  restart: on-failure

services:
  spark-master:
    <<: *spark-common
    container_name: spark_master
    environment:
      SPARK_MODE: 'master'
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 4040
    ports:
      - '7077:7077'
      - '4040:4040'
    depends_on:
      spark-init:
        condition: service_completed_successfully

  spark-worker:
    <<: *spark-common
    container_name: spark_worker
    environment:
      SPARK_MODE: 'worker'
      SPARK_MASTER_URL: 'spark://spark-master:7077'
      SPARK_WORKER_MEMORY: '1G'
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_WEBUI_PORT: 4041
    ports:
      - '4041:4041'
    depends_on:
      spark-init:
        condition: service_completed_successfully

  spark-init:
    <<: *spark-common
    container_name: spark_init
    user: "0:0"
    entrypoint: /bin/bash
    command:
      - -c
      - |
        install_packages wget
        wget -nc https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar -P /spark-jars/
        wget -nc https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.6/hadoop-aws-3.3.6.jar -P /spark-jars/
        chown -R 1001 /spark-jars/
    volumes:
      - spark_jars:/spark-jars
    
  metastore-db:
    image: *postgres-image
    container_name: metastore_db
    environment:
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: 'postgres'
      POSTGRES_DB: 'metastore'
    ports:
      - '5432'
    volumes:
      - hive_pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: on-failure

  metastore:
    image: *hive-image
    container_name: metastore
    environment:
      SERVICE_NAME: 'metastore'
      SERVICE_OPTS: |- 
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver 
        -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://metastore-db:5432/metastore 
        -Djavax.jdo.option.ConnectionUserName=postgres 
        -Djavax.jdo.option.ConnectionPassword=postgres
      HIVE_AUX_JARS_PATH: /opt/hive/aux_jars/
      DB_DRIVER: 'postgres'
    depends_on:
      metastore-db: 
        condition: service_healthy
      metastore-init:
        condition: service_completed_successfully
    volumes:
      - hive_warehouse:/opt/hive/data/warehouse
      - hive_auxjars:/opt/hive/aux_jars/

  metastore-init:
    image: *hive-image
    container_name: metastore_init
    user: 0:0
    entrypoint: /bin/bash
    command:
      - -c
      - |
        apt update && apt install curl -y
        curl --create-dirs -O --output-dir /tmp/aux_jars https://jdbc.postgresql.org/download/postgresql-42.7.1.jar
    volumes:
      - hive_auxjars:/tmp/aux_jars

volumes:
  spark_jars:
    name: spark_jars
  hive_pgdata:
    name: hive_pgdata
  hive_warehouse:
    name: hive_warehouse
  hive_auxjars:
    name: hive_auxjars
