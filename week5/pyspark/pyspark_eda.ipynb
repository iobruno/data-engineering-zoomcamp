{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80675431-e2db-4ee0-805b-abd793a44393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import DataFrame, Row, SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744c78f-3dc4-410d-b64c-0564de35298d",
   "metadata": {},
   "source": [
    "### Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe3882c-0469-435f-8cce-81a529bf2baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 18:42:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "            .master(\"local[*]\")\\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.memory\", \"2g\")\\\n",
    "            .config(\"spark.executor.memory\", \"8g\")\\\n",
    "            .config(\"spark.cores.max\", 8) \\\n",
    "            .appName(\"pyspark-playground\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a2003-84b2-48f1-9fc6-d19f61bab2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FHV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f55c040-3679-4311-9964-65f5a85499ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhv_dataset_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-01.csv.gz\"\n",
    "fhv_filename = Path(fhv_dataset_url).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b583303e-b25c-4f9d-898f-8b86fbe32c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.addFile(fhv_dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9ade0a-da0f-4ef8-95a5-7d0a2eab60f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhv_df = spark.read\\\n",
    "            .option(\"header\", True)\\\n",
    "            .option(\"inferSchema\", True)\\\n",
    "            .csv(f\"file://{SparkFiles.get(fhv_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa77cc5-85c5-4488-85c0-a1a7416843f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fhv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b591e202-7839-47c1-9f52-746f6eb69beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhv_df.createOrReplaceTempView(\"fhv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb2cd0-60a6-4a55-9e50-bfdc161bf23b",
   "metadata": {},
   "source": [
    "### Taxi Lookup Zones Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74c08f9-2558-460c-99fa-9155cba5422a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones_dataset_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
    "zones_filename = Path(zones_dataset_url).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f44baad-921b-49dc-b2ad-f2f02af74144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.addFile(zones_dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab01f942-44c4-486b-b1cc-383e948b0929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "zone_lookup_df = spark.read\\\n",
    "                    .option(\"header\", True)\\\n",
    "                    .option(\"inferSchema\", True)\\\n",
    "                    .csv(f\"file://{SparkFiles.get(zones_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f412f463-1d11-4c1e-ab4e-21ba57283c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_lookup_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56f412e-9a6c-4a8b-a05c-3b951480ed78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zone_lookup_df.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f63da-ec36-4bbf-ab72-815f16dbdf05",
   "metadata": {},
   "source": [
    "### SparkSQL - Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d1f4417-a85e-446f-b93e-0407cc62f23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    WITH t_fhv AS (\n",
    "        SELECT\n",
    "            dispatching_base_num, \n",
    "            Affiliated_base_number as affiliated_base_num,\n",
    "            pickup_datetime,\n",
    "            dropOff_datetime as dropoff_datetime,\n",
    "            PUlocationID as pickup_location_id,\n",
    "            DOlocationID as dropoff_location_id\n",
    "        FROM fhv\n",
    "    ),\n",
    "    \n",
    "    t_zones AS (\n",
    "        SELECT\n",
    "            LocationID as location_id,\n",
    "            Borough as borough,\n",
    "            Zone as zone,\n",
    "            service_zone as service_zone                \n",
    "        FROM zones        \n",
    "    )    \n",
    "    \n",
    "    SELECT \n",
    "        f.dispatching_base_num,\n",
    "        f.affiliated_base_num,\n",
    "\n",
    "        -- Pickup Location\n",
    "        f.pickup_datetime,\n",
    "        pu.zone as pickup_zone,\n",
    "        pu.service_zone as pickup_service_zone,\n",
    "        \n",
    "        -- Dropoff Location\n",
    "        f.dropoff_location_id,\n",
    "        do.zone as dropoff_zone,\n",
    "        do.service_zone as dropoff_service_zone\n",
    "                \n",
    "    FROM t_fhv f    \n",
    "    INNER JOIN t_zones pu ON f.pickup_location_id  = pu.location_id\n",
    "    INNER JOIN t_zones do ON f.dropoff_location_id = do.location_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2d9c09-769d-430d-8410-5853866ab1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------------+--------------------+\n",
      "|dispatching_base_num|affiliated_base_num|    pickup_datetime|          pickup_zone|pickup_service_zone|dropoff_location_id|             dropoff_zone|dropoff_service_zone|\n",
      "+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------------+--------------------+\n",
      "|              B00254|             B02356|2019-01-01 00:33:03|      Lenox Hill East|        Yellow Zone|                 52|              Cobble Hill|           Boro Zone|\n",
      "|              B00254|             B00254|2019-01-01 00:03:00|      Lenox Hill West|        Yellow Zone|                237|    Upper East Side South|         Yellow Zone|\n",
      "|              B00254|             B00254|2019-01-01 00:45:48|Upper East Side South|        Yellow Zone|                236|    Upper East Side North|         Yellow Zone|\n",
      "|              B00254|             B00254|2019-01-01 00:37:39|         Midtown East|        Yellow Zone|                 85|                  Erasmus|           Boro Zone|\n",
      "|              B00254|             B00254|2019-01-01 00:35:06|Upper East Side South|        Yellow Zone|                246|West Chelsea/Hudson Yards|         Yellow Zone|\n",
      "+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, 100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ec5d28-fd81-4232-94c5-1524927ead0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- affiliated_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- pickup_zone: string (nullable = true)\n",
      " |-- pickup_service_zone: string (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- dropoff_zone: string (nullable = true)\n",
      " |-- dropoff_service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c2b98-35df-4358-885f-7c26333851c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
