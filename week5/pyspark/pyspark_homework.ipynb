{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232d3f5c-f2dd-481f-ae8e-ef094e730a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import dayofmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977e36f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/iobruno/Vault/credentials/iobruno-training-gcp_terraform-admin.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a62ca-14ce-448e-bb21-b4a8c4bb173d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f21eac-4d77-4023-8b27-089928c16c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/02 23:32:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "            .master(\"local[*]\")\\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.memory\", \"2g\")\\\n",
    "            .config(\"spark.executor.memory\", \"8g\")\\\n",
    "            .config(\"spark.cores.max\", 8) \\\n",
    "            .appName(\"pyspark-playground\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16de8def-2ede-473b-8701-972b0c2b1631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd08740a-f7d2-41f7-9c87-267e11b6122f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark._jsc.hadoopConfiguration()\\\n",
    "    .set(\"google.cloud.auth.service.account.json.keyfile\", os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfc512-824a-4c99-af3c-66f384aba4f9",
   "metadata": {},
   "source": [
    "## Load Datasets from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22456092-e53c-4df1-baf7-f78861433a32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv: DataFrame = spark.read\\\n",
    "                    .option(\"header\", True)\\\n",
    "                    .option(\"inferSchema\", True)\\\n",
    "                    .csv(\"gs://iobruno_datalake_raw/dtc_ny_taxi_tripdata/fhvhv/fhvhv_tripdata_2021-06.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda76359-88cc-4b32-a7c7-ff3b48c51097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones: DataFrame = spark.read\\\n",
    "                    .option(\"header\", True)\\\n",
    "                    .option(\"inferSchema\", True)\\\n",
    "                    .csv(\"gs://iobruno_datalake_raw/dtc_ny_taxi_tripdata/zone_lookup/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbbe6e36-94a1-48fb-875a-9d9ebd5dc13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhvhv.createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7347b30-97d5-4b47-99d6-63d38a579ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca37d5-a578-4572-9713-f11880cf8239",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375c4694-dbce-4a06-8851-6f548982cb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "    SELECT \n",
    "        dispatching_base_num,\n",
    "        Affiliated_base_number as affiliated_base_num,\n",
    "        PULocationID as pickup_location_id,\n",
    "        DOLocationID as dropoff_location_id,\n",
    "        SR_Flag as sr_flag,\n",
    "        pickup_datetime,\n",
    "        dropoff_datetime\n",
    "    FROM fhvhv\n",
    "    \n",
    "\"\"\").createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8182556e-8854-4fad-95ec-0b7e2b1eb898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    \n",
    "    SELECT\n",
    "        LocationID as location_id,\n",
    "        Borough as borough,\n",
    "        Zone as zone,\n",
    "        service_zone                \n",
    "    FROM zones\n",
    "    \n",
    "\"\"\").createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835f303-8b53-4803-ba43-adb6873af658",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1\n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f764da54-67b5-4d66-acac-f34bccc5a0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d835f4-cba9-40a9-b499-930ebb7585f9",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons. We will use this dataset for all the remaining questions.  \n",
    "Repartition it to 12 partitions and save it to parquet. What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB). Select the answer which most closely matches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f6fd1c-d391-4915-835e-f31fad85a88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"SELECT * FROM fhvhv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16b75697-43b7-40fd-8425-d1d660d8a4af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(12)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"/tmp/dtc/fhvhv-w5q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a31ba-76c8-4964-a4c1-ba1279eea57c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3\n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15? Consider only trips that started on June 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e163f54d-63e7-4203-b0eb-fe6ee76f7bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(day_of_month=15, num_trips=452470)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "    WITH tripdata AS (\n",
    "        SELECT\n",
    "            dayofmonth(pickup_datetime) as day_of_month,\n",
    "            count(1) as num_trips\n",
    "        FROM\n",
    "            fhvhv\n",
    "        GROUP BY\n",
    "            dayofmonth(pickup_datetime)\n",
    "    )\n",
    "    SELECT * FROM tripdata t\n",
    "    WHERE t.day_of_month = 15\n",
    "    \n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e0205-73fb-4462-b280-b71bb74cc680",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip. How long was the longest trip in Hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0792b43b-36a6-463a-ae42-02c316d5cc26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(duration_in_hours=66.8788888888889)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "    WITH tripdata AS (\n",
    "        SELECT\n",
    "            pickup_location_id,\n",
    "            dropoff_location_id,\n",
    "            pickup_datetime,\n",
    "            dropoff_datetime,\n",
    "            (CAST(dropoff_datetime as LONG) - CAST(pickup_datetime as LONG)) as duration_in_secs\n",
    "        FROM\n",
    "            fhvhv\n",
    "    ),\n",
    "    \n",
    "    trip_duration AS (\n",
    "        SELECT \n",
    "            (duration_in_secs/3600) as duration_in_hours,\n",
    "            dense_rank() OVER( ORDER BY duration_in_secs DESC ) as rnk\n",
    "        FROM tripdata t\n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        td.duration_in_hours\n",
    "    FROM trip_duration td\n",
    "    WHERE td.rnk = 1\n",
    "\n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e08bed-582a-4aa6-8537-9ddad4b513c8",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark [Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv).  \n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ab7cf3-48f4-471b-9164-6568899c3ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(pickup_location_id=61, zone='Crown Heights North', num_trips=231279, rnk=1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    \n",
    "    WITH trip_count_per_location AS (\n",
    "        SELECT \n",
    "            f.pickup_location_id,\n",
    "            count(1) as num_trips,\n",
    "            dense_rank() over (order by count(1) desc) as rnk\n",
    "        FROM fhvhv f\n",
    "        GROUP BY f.pickup_location_id\n",
    "    ) \n",
    "    \n",
    "    SELECT \n",
    "        t.pickup_location_id,\n",
    "        z.zone,\n",
    "        t.num_trips,\n",
    "        t.rnk\n",
    "    FROM trip_count_per_location t\n",
    "    INNER JOIN zones z ON t.pickup_location_id = z.location_id\n",
    "    WHERE t.rnk = 1\n",
    "    \n",
    "\"\"\").take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e6051-1fb5-45bd-8241-a127d4fcae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
